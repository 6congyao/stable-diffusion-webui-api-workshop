{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c774a659",
   "metadata": {},
   "source": [
    "Here we will show you how to use stable-diffusion-webui to generate image with Lora and ControlNet support. The stable-diffusion-webui will be hostd at Amazon SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016ec68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "import boto3\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2afbb91",
   "metadata": {},
   "source": [
    "Prepare models directory and organize the structure as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95481c68-3b3c-4138-b794-ff2d9583b977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p models\n",
    "!mkdir -p models/Stable-diffusion\n",
    "!mkdir -p models/ControlNet\n",
    "!mkdir -p models/Lora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4246b642",
   "metadata": {},
   "source": [
    "Logout from AWS public ECR to avoid the authentication token is expired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker logout public.ecr.aws"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a615bee",
   "metadata": {},
   "source": [
    "Build Docker image and push to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788db8d-3b69-4807-b83e-eaff32195190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./build_and_push.sh.lite $region_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dcdc938",
   "metadata": {},
   "source": [
    "Install Huggingface Hub toolkit and login with your Huggingface access token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f1a33-f2b3-41a5-a5ad-fcfb2d90e2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "!huggingface-cli login --token [Your-huggingface-access-token]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7577b6e",
   "metadata": {},
   "source": [
    "Download Stable-diffuion models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e6085-3a8b-452d-87f8-6f820ffd75d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(\n",
    "    repo_id=\"stabilityai/stable-diffusion-2-1\", \n",
    "    filename=\"v2-1_768-ema-pruned.ckpt\", \n",
    "    local_dir=\"models/Stable-diffusion/\"\n",
    ")\n",
    "hf_hub_download(\n",
    "    repo_id=\"runwayml/stable-diffusion-v1-5\", \n",
    "    filename=\"v1-5-pruned.ckpt\", \n",
    "    local_dir=\"models/Stable-diffusion/\"\n",
    ")\n",
    "!wget \"https://github.com/Stability-AI/stablediffusion/blob/main/configs/stable-diffusion/v2-inference-v.yaml\" -O models/Stable-diffusion/v2-1_768-ema-pruned.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7c0d6a6",
   "metadata": {},
   "source": [
    "Download ControlNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3f273-60b8-4ed9-bb8c-eea7762b3f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_hub_download(\n",
    "    repo_id=\"lllyasviel/ControlNet\", \n",
    "    filename=\"models/control_sd15_canny.pth\", \n",
    "    local_dir=\"models/ControlNet/\"\n",
    ")\n",
    "!mv models/ControlNet/models/control_sd15_canny.pth models/ControlNet/control_sd15_canny.pth\n",
    "!rm -rf models/ControlNet/models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff0680f7",
   "metadata": {},
   "source": [
    "Download Lora model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e1108-2cb4-42fa-9bc5-744ec226fa0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget \"https://civitai.com/api/download/models/7627\" -O models/Lora/2bNierAutomataLora_v2b.safetensors\n",
    "\n",
    "hf_hub_download(\n",
    "    repo_id=\"andite/anything-v4.0\", \n",
    "    filename=\"anything-v4.5-pruned.safetensors\", \n",
    "    local_dir=\"models/Lora/\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4097e342",
   "metadata": {},
   "source": [
    "Compress Stable-diffusion, ControlNet and Lora models as tar.gz archieve file when models/model.tar.gz doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c5ec6-03f3-4aed-ba43-d266dc04ee67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "![ ! -f models/model.tar.gz ] && !cd models && tar czvfh model.tar.gz Stable-diffusion ControlNet Lora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b13f13b",
   "metadata": {},
   "source": [
    "Download s5cmd which is a very fast S3 and local filesystem execution tool and place it under directory - tools/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d286b5c-a500-4010-b8ae-b6fd8fc1338f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz -O tools/s5cmd_2.0.0_Linux-64bit.tar.gz\n",
    "!tar xzvf tools/s5cmd_2.0.0_Linux-64bit.tar.gz -C tools/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "790c2023",
   "metadata": {},
   "source": [
    "Upload file - models/model.tar.gz to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21e8a1-86c4-4f83-98a4-cdb5204aa9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = \"s3://{0}/stable-diffusion-webui/data/model.tar.gz\".format(bucket)\n",
    "!tools/s5cmd cp models/model.tar.gz $model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d24f73-e016-4b16-b5b2-cefb51e356a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = None\n",
    "image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/all-in-one-ai-stable-diffusion-webui-inference-api:latest'.format(account_id, region_name)\n",
    "base_name = sagemaker.utils.base_name_from_image(image_uri)\n",
    "model_environment = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT': '1200'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974688b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d421d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    name = model_name,\n",
    "    model_data = model_data,\n",
    "    role = role,\n",
    "    image_uri = image_uri,\n",
    "    env = model_environment,\n",
    "    predictor_cls = Predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4da136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "instance_type = 'ml.g4dn.2xlarge'\n",
    "instance_count = 1\n",
    "async_config = AsyncInferenceConfig(output_path='s3://{0}/{1}/asyncinvoke/out/'.format(bucket, 'stable-diffusion-webui'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bb3ab80",
   "metadata": {},
   "source": [
    "Here to be simplied, we use real-time inference. However it has some limitations by nature. Real-time inference is suitable for workloads where payload sizes are up to 6MB and need to be processed with low latency requirements in the order of milliseconds or seconds Async inference is more suitable for workloads with large payload sizes and long inference processing times. Async inference also works for stable-diffusion-webui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb508a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type = instance_type, \n",
    "    initial_instance_count = instance_count\n",
    "    #async_inference_config = async_config\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f54519ea",
   "metadata": {},
   "source": [
    "LoRA (Low-Rank Adaptation of Large Language Models) models have become the standard to extend the Stable Diffusion models. Let's use Lora model to generate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d00e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    'task': 'text-to-image', \n",
    "    'txt2img_payload': {\n",
    "        'enable_hr': False, \n",
    "        'denoising_strength': 0.7, \n",
    "        'firstphase_width': 0, \n",
    "        'firstphase_height': 0, \n",
    "        'prompt': 'yorha no. 2 type b, 1girl, bangs, black blindfold, black dress, black gloves, black hairband, blindfold, blindfold removed, breasts, cleavage cutout, clothing cutout, commentary request, dress, gloves, hairband, half-closed eyes, hand up, highres, io (sinking=carousel), juliet sleeves, long sleeves, looking at viewer, medium breasts, mole, mole under mouth, nier (series), nier automata, no blindfold, parted lips, puffy sleeves, short hair, solo, thighhighs, turtleneck, upper body, white hair, bokeh <lora:2bNierAutomataLora_v2b:0.5>', \n",
    "        'styles': ['None', 'None'], \n",
    "        'seed': -1.0, \n",
    "        'subseed': -1.0, \n",
    "        'subseed_strength': 0, \n",
    "        'seed_resize_from_h': 0, \n",
    "        'seed_resize_from_w': 0, \n",
    "        'sampler_index': 'DPM++ SDE Karras', \n",
    "        'batch_size': 1, \n",
    "        'n_iter': 1, \n",
    "        'steps': 20, \n",
    "        'cfg_scale': 7, \n",
    "        'width': 512, \n",
    "        'height': 512, \n",
    "        'restore_faces': False, \n",
    "        'tiling': False, \n",
    "        'negative_prompt': '(worst quality, low quality:1.3)', \n",
    "        'eta': 1, \n",
    "        's_churn': 0, \n",
    "        's_tmax': None, \n",
    "        's_tmin': 0, \n",
    "        's_noise': 1, \n",
    "        'override_settings': {}, \n",
    "        'script_args': [0, False, False, False, \"\", 1, \"\", 0, \"\", True, False, False]}\n",
    "}\n",
    "\n",
    "#prediction = predictor.predict_async(inputs)\n",
    "prediction = predictor.predict(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da2775d8",
   "metadata": {},
   "source": [
    "Process the generated images from real-time inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f99d20-733a-4190-b026-30f27e2b3834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "for image in prediction['images']:\n",
    "    image = Image.open(io.BytesIO(base64.b64decode(image)))\n",
    "    image.show()\n",
    "    image.save('0.jpg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c67fda86",
   "metadata": {},
   "source": [
    "Delete endpoint when the experiment is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f789711d",
   "metadata": {},
   "source": [
    "Wait until the async inference is done in case when we use async inferece for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0aad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "  max_attempts=100, #  number of attempts\n",
    "  delay=10 #  time in seconds to wait between attempts\n",
    "  )\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d76bdd67",
   "metadata": {},
   "source": [
    "Helper function for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02663546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from PIL import Image\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find('/', 5)\n",
    "    bucket = s3uri[5 : pos]\n",
    "    key = s3uri[pos + 1 : ]\n",
    "    return bucket, key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b04df861",
   "metadata": {},
   "source": [
    "Process the generated images from async inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc78a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import base64\n",
    "try:\n",
    "    bucket, key = get_bucket_and_key(prediction.output_path)\n",
    "    obj = s3_resource.Object(bucket, key)\n",
    "    body = obj.get()['Body'].read().decode('utf-8') \n",
    "    for image in json.loads(body)['images']:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(image)))\n",
    "        image.show()\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de653c58",
   "metadata": {},
   "source": [
    "Create auto scaling group for SageMaker endpoint in case you want to scale it based on particul metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoscaling_group_for_sagemaker_endpoint(endpoint_name, min_capcity = 1, max_capcity = 2, target_value = 5):\n",
    "    # application-autoscaling client\n",
    "    asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "    # This is the format in which application autoscaling references the endpoint\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "    # Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "    response = asg_client.register_scalable_target(\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        MinCapacity=min_capcity,\n",
    "        MaxCapacity=max_capcity,\n",
    "    )\n",
    "\n",
    "    response = asg_client.put_scaling_policy(\n",
    "        PolicyName=f'Request-ScalingPolicy-{endpoint_name}',\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        PolicyType=\"TargetTrackingScaling\",\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            \"TargetValue\": target_value,\n",
    "            \"CustomizedMetricSpecification\": {\n",
    "                \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n",
    "                \"Namespace\": \"AWS/SageMaker\",\n",
    "                \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": endpoint_name}],\n",
    "                \"Statistic\": \"Average\",\n",
    "            },\n",
    "            \"ScaleInCooldown\": 600, # duration until scale in begins (down to zero)\n",
    "            \"ScaleOutCooldown\": 300 # duration between scale out attempts\n",
    "        },\n",
    "    )\n",
    "\n",
    "create_autoscaling_group_for_sagemaker_endpoint(predictor.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
